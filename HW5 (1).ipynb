{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec58ef79",
   "metadata": {},
   "source": [
    "1.1 Key factor for testable ideas: I think it can examined and tested statistically if it can be measured or quantified. The key factor is whether the idea can be translated into measurable data. Statistical testing requires that the idea is specific enough to be tested against observable outcomes using probability.\n",
    "1.2 Criteria for a good null hypothesis: A good null hypothesis is a clear, testable statement that assumes no effect or no difference in the context of the test. It must be falsifiable, meaning that it can be disproven based on the evidence from the sample data.\n",
    "1.3 Difference between null and alternative hypotheses:\n",
    "The null hypothesis (H₀) is the default position, stating that there is no effect, no difference, or no association between variables being tested. It assumes any observed differences are due to chance.\n",
    "The alternative hypothesis (H₁) is what you aim to support. It proposes that there is a significant effect or a difference, meaning that any observed results are not solely due to random chance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b4b17a",
   "metadata": {},
   "source": [
    "1 chatbot Here’s the summary in **Markdown** format, with the link you provided:\n",
    "\n",
    "```markdown\n",
    "### Null Hypothesis (H₀) vs. Alternative Hypothesis (H₁ or Hₐ)\n",
    "\n",
    "#### 1. **Null Hypothesis (H₀)**:\n",
    "- Assumes **no effect**, **no difference**, or **no relationship** between variables.\n",
    "- Acts as the default or baseline hypothesis.\n",
    "- Suggests that any observed differences are due to random chance or variability.\n",
    "- **Non-directional**, often stating \"no difference.\"\n",
    "- Researchers aim to test if there is enough evidence to **reject the null hypothesis**.\n",
    "- **Example**: \"There is no difference in blood pressure between individuals who exercise and those who don’t.\"\n",
    "\n",
    "#### 2. **Alternative Hypothesis (H₁ or Hₐ)**:\n",
    "- Proposes that there **is an effect**, a **difference**, or a **relationship** between variables.\n",
    "- Represents the researcher’s claim or theory.\n",
    "- Can be **non-directional** (two-tailed) or **directional** (one-tailed), depending on whether it specifies the direction of the effect.\n",
    "- Researchers seek evidence to support the alternative hypothesis by rejecting the null hypothesis.\n",
    "- **Example**: \"There is a difference in blood pressure between individuals who exercise and those who don’t.\"\n",
    "\n",
    "### Key Differences:\n",
    "- **H₀** is tested to see if it can be rejected, while **H₁** is accepted when the null hypothesis is rejected.\n",
    "- **H₀** assumes no effect, while **H₁** suggests a real effect or difference.\n",
    "- **H₀** is neutral and objective, whereas **H₁** is the research hypothesis that one aims to prove.\n",
    "\n",
    "In statistical testing, if sufficient evidence supports **H₁**, the null hypothesis is rejected; otherwise, **H₀** is retained.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3936046b",
   "metadata": {},
   "source": [
    "2  [Click here to view additional related information](https://chatgpt.com/share/670dc632-0bf4-8007-84c8-e7b03b7bc77d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d9661f",
   "metadata": {},
   "source": [
    "2.1 I think important to note that outcomes of tests refer to the population parameter, rather than the sample statistic because the propose to the test is for inferences about the population parameter based on sample data, also the sample statistic is sometimes not typical, can only identify part of the data. \n",
    "A population is the entire figure in the dataset.\n",
    "A sample is a part of data taken from the population which for the research.\n",
    "A parameter is a true value or characteristic of the population\n",
    "A statistic is a value calculated from the sample "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630ae02c",
   "metadata": {},
   "source": [
    "2 chatbot Here's a summary of the relationship between **population parameters**, **sample statistics**, and the **outcomes of hypothesis tests**:\n",
    "\n",
    "1. **Population Parameter**\n",
    "   - **Definition**: A fixed, often unknown value that describes a characteristic of the entire population (e.g., population mean \\(\\mu\\), population proportion \\(p\\)).\n",
    "   - **Role**: The goal of hypothesis testing is to draw inferences about population parameters using data from a sample.\n",
    "2. **Sample Statistic**\n",
    "   - **Definition**: A value calculated from sample data (e.g., sample mean \\(\\bar{x}\\), sample proportion \\(\\hat{p}\\)), used to estimate the corresponding population parameter.\n",
    "   - **Role**: Sample statistics serve as the basis for calculating test statistics (e.g., t-statistic, z-score), which are used to make decisions about population parameters in hypothesis tests.\n",
    "\n",
    "3. **Hypothesis Test Outcomes**\n",
    "   - **Reject the Null Hypothesis (\\(H_0\\))**: Concluding that there is enough evidence to suggest the population parameter differs from the hypothesized value, based on the sample statistic.\n",
    "   - **Fail to Reject the Null Hypothesis (\\(H_0\\))**: Concluding that there is not enough evidence to suggest the population parameter differs from the hypothesized value.\n",
    "   \n",
    "4. **Types of Errors**\n",
    "   - **Type I Error** (False Positive): Rejecting \\(H_0\\) when the population parameter actually supports it.\n",
    "   - **Type II Error** (False Negative): Failing to reject \\(H_0\\) when the population parameter differs from the hypothesized value.\n",
    "   \n",
    "5. **Power of the Test**\n",
    "   - The probability of correctly rejecting \\(H_0\\) when the alternative hypothesis is true. Larger sample sizes or greater differences between the sample statistic and null hypothesis value increase power.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff36151",
   "metadata": {},
   "source": [
    "2 https://chatgpt.com/share/670ef10b-4b68-8007-9d73-6a9acbc18e26"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533a2843",
   "metadata": {},
   "source": [
    "In hypothesis testing, the sentence is emphasizing that the conclusions we draw from a test are about the population as a whole, not just the specific data sample we have. Here’s a simple breakdown of the statistical terms in non-technical language:\n",
    "\n",
    "1. **Population**: This is the entire group you're interested in learning about (for example, all the people in a country).\n",
    "   \n",
    "2. **Sample**: This is a smaller group you actually collect data from (for example, 100 people surveyed).\n",
    "\n",
    "3. **Parameter**: A parameter is a number that describes something about the population (like the true average income of all people in a country, which is usually unknown).\n",
    "\n",
    "4. **Statistic**: A statistic is a number you calculate from your sample (like the average income of the 100 people you surveyed).\n",
    "\n",
    "The key point is that when you run a test, you’re trying to make conclusions about the **population parameter** (like the true average income), not just the **sample statistic** (the average income of the people you surveyed). The hypothesis test helps you assess if the population parameter is likely equal to a specific value (the **null hypothesis**) or different from that value (the **alternative hypothesis**).\n",
    "\n",
    "In short, the result of the test tells us something about the population as a whole, not just the sample.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cf3324",
   "metadata": {},
   "source": [
    "3 When we calculate a p-value in hypothesis testing, we start by assuming that the **null hypothesis** is true. This means we imagine a world where there's no real effect or difference in what we're studying.\n",
    "\n",
    "The reason we do this is to see how unusual or surprising our sample result is under that assumption. We use the **sampling distribution** of the **test statistic**, which shows us all the possible values our statistic (like the sample average) could take if the null hypothesis were true. The p-value tells us the probability of getting a result as extreme as the one we observed, or more extreme, just by chance if the null hypothesis is correct.\n",
    "\n",
    "In other words, if the p-value is very small, it means our observed result is quite unlikely under the null hypothesis, suggesting that the null might not be true.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c2b83c",
   "metadata": {},
   "source": [
    "4 I think a smaller p-value makes the null hypothesis look more ridiculous mean the tests is possible but is not probability. which mean A\n",
    "low P-vable.Also I search When the difference between what is observed and what is expected under the null hypothesis is large,\n",
    "a larger sample size reduces variability and makes it easier to detect smaller effects,or if the data has low variability, these all will make\n",
    "a low p-vable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce12533",
   "metadata": {},
   "source": [
    "4 Chatbot Here's a summary of the key points:\n",
    "\n",
    "Null Hypothesis (H₀): This is the assumption we start with, often stating there is no effect or no difference. In the coin flip example, the null hypothesis is that the coin is fair (P(Heads) = 0.5).\n",
    "\n",
    "Test Statistic: This is a value derived from the data to help assess the null hypothesis. In the example, the test statistic is the number of heads in 10 flips.\n",
    "\n",
    "Sampling Distribution under the Null Hypothesis: This distribution shows all possible outcomes of the test statistic (e.g., how many heads you might get) if the null hypothesis were true. It allows us to see how likely different outcomes are when the null hypothesis holds. For example, with a fair coin, the most likely result in 10 flips is 5 heads, but there’s some probability of getting more or fewer heads.\n",
    "\n",
    "P-value: The p-value tells us how likely our observed test statistic is, given that the null hypothesis is true. A small p-value means the observed result is unlikely under the null hypothesis, which makes the null hypothesis look less believable.\n",
    "\n",
    "Example of Sampling Distribution: In the coin flip example, the sampling distribution under H₀ (a fair coin) would show that 5 heads is the most probable result. However, if we observe an extreme outcome like 9 heads, the p-value would be small, suggesting that the null hypothesis (that the coin is fair) might be incorrect.\n",
    "\n",
    "Key Concept:\n",
    "The sampling distribution under the null hypothesis helps us understand the likelihood of our observed data, and a small p-value indicates that the data is unlikely if the null hypothesis were true, pushing us to reconsider or reject the null hypothesis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ec965f",
   "metadata": {},
   "source": [
    "4. chatbot https://chatgpt.com/share/670efad4-1810-8007-b20e-fb342b5aaa93"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56394e06",
   "metadata": {},
   "source": [
    "5 ### Problem Breakdown\n",
    "\n",
    "1. **Null Hypothesis** \\( H_0 \\): The population of humans does not have a preference for tilting their heads left or right when kissing. This implies a **50/50 chance** of head tilt direction, just like flipping a fair coin.\n",
    "   \n",
    "2. **Alternative Hypothesis** \\( H_1 \\): The population of humans does have a preference for tilting their heads in a specific direction when kissing (in this case, more to the right).\n",
    "\n",
    "3. **Observed Statistic**: Out of 124 couples, 80 tilted their heads to the right. This corresponds to approximately 64.5%.\n",
    "\n",
    "Simulating a p-value\n",
    "\n",
    "To simulate a p-value using a \"50/50 coin-flipping\" model under the assumption of the null hypothesis, we'll simulate the head tilting behavior of 124 couples assuming no preference for left or right (a 50/50 chance for each couple). Here's how you can calculate this p-value:\n",
    "\n",
    "1. **Set up the simulation**:\n",
    "   - Flip a virtual coin 124 times, where each flip represents a couple's head tilt (Heads = right tilt, Tails = left tilt).\n",
    "   - Count the number of heads (right tilts) in each simulation.\n",
    "   - Repeat this process many times (say, 10,000 times) to build a distribution of possible outcomes if there really is no preference (null hypothesis).\n",
    "\n",
    "2. **Calculate the p-value**:\n",
    "   - The p-value is the proportion of simulated outcomes where the number of right tilts is 80 or greater (since 80 out of 124 couples tilted right in the observed data).\n",
    "   \n",
    "3. **Determine level of evidence**:\n",
    "   - Based on the strength of evidence table provided in your material, you can interpret the calculated p-value and decide whether the observed result provides enough evidence to reject the null hypothesis.\n",
    "\n",
    " Python Code Example\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Set up simulation parameters\n",
    "n_simulations = 10000  # Number of simulations\n",
    "n_couples = 124  # Number of couples\n",
    "observed_right_tilts = 80  # Observed right tilts\n",
    "\n",
    "# Simulate 10,000 trials of 124 coin flips (50/50 probability)\n",
    "simulated_trials = np.random.binomial(n=n_couples, p=0.5, size=n_simulations)\n",
    "\n",
    "# Calculate p-value (proportion of simulations where right tilts >= 80)\n",
    "p_value = np.mean(simulated_trials >= observed_right_tilts)\n",
    "\n",
    "p_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b057db6",
   "metadata": {},
   "source": [
    "6 No, a smaller p-value cannot definitively prove that the null hypothesis is false. A p-value tells us how surprising or unlikely the observed data is **if the null hypothesis were true**, but it does not provide absolute proof. A small p-value suggests strong evidence against the null hypothesis, but it does not guarantee that the null is false.\n",
    "\n",
    "Similarly, in the case of Fido from the \"second pre-lecture video,\" a p-value cannot definitively prove that Fido is innocent or guilty. A p-value can only indicate how consistent the evidence is with the assumption of innocence (the null hypothesis). Even with a very low or high p-value, it’s always possible that the result is due to random chance, so we never get a \"definitive\" answer.\n",
    "\n",
    "No matter how low (or high) a p-value is, it does not **prove** anything with certainty—it only gives a measure of the strength of the evidence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93585ce",
   "metadata": {},
   "source": [
    "7 import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    " Sample data (hypothetical example)\n",
    "observed_mean = 0.52\n",
    "null_hypothesis_mean = 0.5\n",
    "std_error = 0.03\n",
    "n = 100  # Sample size\n",
    "\n",
    " Calculate test statistic (Z-score)\n",
    "z_score = (observed_mean - null_hypothesis_mean) / std_error\n",
    "\n",
    "Two-tailed p-value\n",
    "p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
    "\n",
    "print(f\"Two-sided p-value: {p_value}\")\n",
    "\n",
    "One-sided p-value (right tail test, H1: mu > mu_0)\n",
    "p_value_one_sided = 1 -\n",
    "One-sided vs. Two-sided Hypothesis Tests\n",
    "\n",
    "Before discussing the code changes, let’s review the distinction between one-sided (one-tailed) and two-sided (two-tailed) hypothesis tests:\n",
    "\n",
    "- A **two-sided** test checks if the population parameter is **different** from the hypothesized value, without specifying the direction (greater or less).\n",
    "  - Null Hypothesis \\( H_0: \\mu = \\mu_0 \\)\n",
    "  - Alternative Hypothesis \\( H_1: \\mu \\neq \\mu_0 \\)\n",
    "  - This test looks at both \"tails\" of the distribution, accounting for deviations in either direction.\n",
    "\n",
    "- A **one-sided** test checks if the parameter is either **greater than** or **less than** the hypothesized value, depending on the direction of interest.\n",
    "  - Null Hypothesis \\( H_0: \\mu \\leq \\mu_0 \\) or \\( H_0: \\mu \\geq \\mu_0 \\)\n",
    "  - Alternative Hypothesis \\( H_1: \\mu > \\mu_0 \\) or \\( H_1: \\mu < \\mu_0 \\)\n",
    "  - This test looks only at one \"tail\" of the distribution.\n",
    "\n",
    "Adjusting the Code for a One-sided Test\n",
    "\n",
    "Here’s how you would adjust the code to compute a **one-sided** p-value for the vaccine data analysis assignment, compared to the original **two-sided** test:\n",
    "\n",
    " Original (Two-sided) Test Code\n",
    "The code for the two-sided test might look something like this:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data (hypothetical example)\n",
    "observed_mean = 0.52\n",
    "null_hypothesis_mean = 0.5\n",
    "std_error = 0.03\n",
    "n = 100  # Sample size\n",
    "\n",
    "# Calculate test statistic (Z-score)\n",
    "z_score = (observed_mean - null_hypothesis_mean) / std_error\n",
    "\n",
    "# Two-tailed p-value\n",
    "p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
    "\n",
    "print(f\"Two-sided p-value: {p_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bd24c5",
   "metadata": {},
   "source": [
    "8 \n",
    "8.1Problem Introduction\n",
    "\n",
    "This project revisits a famous hypothesis test first proposed by Ronald Fisher, in which a subject claims to taste the difference between tea poured before milk or milk poured before tea. In this adapted experiment, 80 STA130 students were given a single cup of tea and asked to determine whether the milk or tea was poured first. Of the 80 students, 49 correctly identified the order. The goal is to analyze whether this result could have occurred by chance or if there is evidence that STA130 students can distinguish the pouring order.\n",
    "\n",
    "8.2 Relationship between this Experiment and Fisher's Original Experiment\n",
    "\n",
    "While Fisher's original experiment involved a single subject (Dr. Bristol) who claimed the ability to distinguish between two different tea-making methods, this adaptation is broader, involving a larger group of students (80). This changes the nature of the population and parameter. In Fisher's case, the parameter was personalized—Dr. Bristol's specific ability to tell the difference. In this case, the parameter becomes a more abstract measure of the population of STA130 students and their ability to identify the correct pouring method.\n",
    "\n",
    "Null Hypothesis and Alternative Hypothesis\n",
    "\n",
    "- **Null Hypothesis (H₀):** The proportion of STA130 students who can correctly identify whether the milk or tea was poured first is equal to that expected by random guessing (50%).\n",
    "\n",
    "  - **Formal Version:** \\( H_0: p = 0.5 \\)\n",
    "\n",
    "  - **Informal Statement:** STA130 students are no better than random guessers when identifying whether the tea or milk was poured first.\n",
    "\n",
    "- **Alternative Hypothesis (H₁):** The proportion of STA130 students who can correctly identify whether the milk or tea was poured first is greater than that expected by random guessing.\n",
    "\n",
    "  - **Formal Version:** \\( H_1: p > 0.5 \\)\n",
    "\n",
    "  - **Informal Statement:** STA130 students are better than random guessers when identifying whether the tea or milk was poured first.\n",
    "\n",
    "8.3 Quantitative Analysis\n",
    "\n",
    "Test Statistic\n",
    "\n",
    "The parameter of interest is the proportion of students who can correctly identify the pouring order. The observed test statistic is the number of students who correctly guessed, which is \\( 49 \\) out of 80.\n",
    "Hypothesis Test Approach\n",
    "\n",
    "1. **Proportion Testing**:\n",
    "   Use a one-sample z-test for proportions to compare the observed proportion (\\( \\hat{p} = \\frac{49}{80} = 0.6125 \\)) against the null hypothesis proportion of 0.5.\n",
    "\n",
    "2. **Calculation**:\n",
    "   The test statistic for a one-sample proportion test is given by:\n",
    "\n",
    "   \\[\n",
    "   z = \\frac{\\hat{p} - p_0}{\\sqrt{\\frac{p_0(1 - p_0)}{n}}}\n",
    "   \\]\n",
    "\n",
    "   where:\n",
    "   - \\( \\hat{p} \\) is the observed proportion (0.6125),\n",
    "   - \\( p_0 \\) is the null hypothesis proportion (0.5),\n",
    "   - \\( n \\) is the sample size (80).\n",
    "\n",
    "3. **P-value**:\n",
    "   The p-value will be calculated based on the z-score from the test statistic, determining whether the result is statistically significant.\n",
    "\n",
    "4. **Confidence Interval** (Optional):\n",
    "   You could also calculate a 95% confidence interval for the proportion to assess the range in which the true proportion might lie. If 0.5 is not in the interval, you could reject the null hypothesis.\n",
    "\n",
    "8.4 Methodology Code and Explanations\n",
    "\n",
    "You can write Python code to carry out the hypothesis test and compute the test statistic and p-value. Here’s a template for that:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Given data\n",
    "n = 80  # Sample size\n",
    "x = 49  # Number of students who correctly identified the pouring method\n",
    "p_hat = x / n  # Observed proportion\n",
    "p_0 = 0.5  # Null hypothesis proportion\n",
    "\n",
    "# Z-test statistic\n",
    "z = (p_hat - p_0) / np.sqrt(p_0 * (1 - p_0) / n)\n",
    "\n",
    "# P-value for a one-tailed test\n",
    "p_value = 1 - stats.norm.cdf(z)\n",
    "\n",
    "# Display results\n",
    "print(f\"Test Statistic (Z): {z}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Optional: Confidence Interval\n",
    "alpha = 0.05  # 95% confidence level\n",
    "ci_lower = p_hat - stats.norm.ppf(1 - alpha/2) * np.sqrt(p_hat * (1 - p_hat) / n)\n",
    "ci_upper = p_hat + stats.norm.ppf(1 - alpha/2) * np.sqrt(p_hat * (1 - p_hat) / n)\n",
    "\n",
    "print(f\"95% Confidence Interval for p: [{ci_lower:.4f}, {ci_upper:.4f}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2f8748",
   "metadata": {},
   "source": [
    "9 yes, I reviewed the course wiki-textbook and interacted with a ChatBot."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
